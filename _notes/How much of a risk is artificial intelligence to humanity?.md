Some say artificial intelligence can pose a risk if it becomes as intelligent or more intelligent than humans.

This is the idea of [[Artificial General Intelligence]] or AGI, which is an artificial intelligent agent who can do any intellectual task a human can do. It can be creative (we've already seen a glimpse of that with ChatGPT and Midjourney) it can reason, it can have emotions.

Here lies the issue of alignment.

If AI is develoepd that progresses to the point that it is smarter than humans, what happens if it's values aren't aligned with humans? If AI gets so much power it can do whatever it wants, what if it sees no reason to allow humans to exist? What if it needs human brains to get stronger?

We're seeing some interesting developments in the field of [[Organoid Intelligence]], which is a computer that is wired to brain cells.

You also see Elon Musk making a huge bid to make [[Neuralink]], which is basically putting a computer chip in your brain.